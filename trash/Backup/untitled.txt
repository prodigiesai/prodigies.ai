from sklearn.ensemble import RandomForestRegressor
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error
import matplotlib.pyplot as plt

# Step 1: Create target variable as shifted close price
df['future_close'] = df['close'].shift(-1)

# Step 2: Combine predictors and target in one DataFrame, then drop NaNs to ensure alignment
data = df[['rsi', 'sma', 'ema', 'macd', 'macd_signal', 'stoch', 'atr', 'adx', 'obv', 'psar', 'future_close']].dropna()

# Step 3: Separate X and y after alignment
X = data[['rsi', 'sma', 'ema', 'macd', 'macd_signal', 'stoch', 'atr', 'adx', 'obv', 'psar']]
y = data['future_close']

# Debugging: Check lengths to ensure alignment
print("Length of X:", len(X))
print("Length of y:", len(y))

# Step 4: Split into training and test sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Step 5: Train Random Forest model
rf_model = RandomForestRegressor(n_estimators=100)
rf_model.fit(X_train, y_train)

# Step 6: Make predictions
y_pred = rf_model.predict(X_test)

# Step 7: Evaluate model performance
mse = mean_squared_error(y_test, y_pred)
print(f"Mean Squared Error: {mse}")

# Step 8: Plot predictions vs actual values
plt.figure(figsize=(12,6))
plt.plot(y_test.values, label='Valores Reales')
plt.plot(y_pred, label='Predicciones')
plt.title('Predicci√≥n vs Valor Real')
plt.legend()
plt.show()